<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->



# 6.6 分布式训练的通信协调

通信协调在分布式训练的整体性能中起到了举足轻重的作用。众多软硬件技术在深度学的发展过程中被提出和应用。本节以
GPU为例，介绍目前深度学习中所采用的主流通信技术。

按照方式，通信可分为：机器内通信和机器间通信。前者包含：共享内存、GPUDirect
P2P over PCIe、GPUDirect P2P over NVLink，而后者包含：TCP/IP网络、
RDMA网络和GPUDirect RDMA网络。

## 6.6.1 通信协调的硬件

<center><img src="./img/image34.png" width="600" height="" /></center>
<center>图6-6-1: 常见的加速设备形式 左：HGX卡；右：标准双槽PCIe卡 (<a href=https://www.nvidia.com/en-us/data-center/a100>图片来源</a>) </center>


<center><img src="./img/image35.png" width="600" height="" /></center>
<center>图6-6-2: 多设备通过不同的方式互联 左：HGX 8 GPU互联；右：标准PCIe卡堆叠 (<a href=https://nvidia.com>图片来源</a>) </center>


图示了两种常见的GPU硬件形式（上）以及连接方式（下）：NVLink (300GB/s) vs. PCIe 4.0 (32GB/s)。二者的链路带宽差距高达约10倍。众多实际训练表明，高带宽链路极大地提高了并行训练的总体性能。因此，我们可以看到无论是节点内的多设备以及节点间的网络，链路带宽近些年都取得了大幅提升。


<center><img src="./img/image36.png" width="700" height="" /></center>
<center>图6-6-3: 常见设备互联的带宽 (<a href=https://www.olcf.ornl.gov/wp-content/uploads/2019/12/Summit-NCCL.pdf>图片来源</a>，<a href=https://www.microway.com/hpc-tech-tips/dgx-a100-review-throughput-and-hardware-summary/>A100 NVLink性能数据来源</a>， <a href=https://techcommunity.microsoft.com/t5/azure-global/performance-considerations-for-large-scale-deep-learning/ba-p/2693834>A100 4节点网络性能数据(187 GB/s)来源</a>)</center>

除了NVIDIA之外，其它加速器硬件厂商也提出了类似的高速数据链路。下图分别是AMD和隧原科技设计的加速器互联硬件。


<center><img src="./img/image37.png" width="600" height="" /></center>
<center>图6-6-4: 常见的一些PCIe设备互联硬件背板 左：OCP Summit (<a href=https://146a55aca6f00848c565-a7635525d40ac1c70300198708936b4e.ssl.cf1.rackcdn.com/images/442f418201b7eb32089aa12895ee78977d03bea1.pdf>图片来源</a>)， 右：Enflame T10 (<a href=https://www.enflame-tech.com/support>图片来源</a>)</center>



而依据GPU的硬件互联结构，可以绘制出互联拓扑。目前的互联结构存在多种不同的拓扑。如下图所示，最为常见的 PCI only 连结仅使用标准的PCI/PCIe接口将加速卡与系统的其它部分连接起来。受限于PCIe的带宽限制（例如PCIe 4.0 x16 单向传输带宽为 31.508 GB/s）以及树形的连接拓扑，PCIe在设备互联上具有天然的障碍。因此，在GPU高性能计算中常配备专用高速链路实现高带宽的卡间互联，包括DGX-1/P9中的卡间直连，以及DGX-2/3中采用交换机形式的NVSwitch。

<center><img src="./img/image38.png" width="600" height="" /></center>
<center>图6-6-5: 常见的加速设备硬件互联拓扑 (<a href=https://www.olcf.ornl.gov/wp-content/uploads/2019/12/Summit-NCCL.pdf>图片来源</a>)</center>


除了通信拓扑，通信的协议也在不断迭代。如下图的**GPUDirect
P2P**，GPU可以直接访问另一GPU的显存，无需CPU介入或系统内存中转，从而实现“零拷贝（zero-copy）”。
开启这项功能的对于GPU以及之间的连接方式等硬件条件均有要求：GPU属于Tesla / Quadra 专业级别，并且GPU之间通过NVLink互联或者属于同一PCIe root（例如，不允许跨NUMA node）。


<center><img src="./img/image39.png" width="600" height="" /></center>
<center>图6-6-6: 传统通过PCIe和CPU内存进行的设备间通信 (<a href=http://developer.download.nvidia.com/compute/cuda/4_0/CUDA_Toolkit_4.0_Overview.pdf>图片来源</a>) </center>

<center><img src="./img/image40.jpeg" width="600" height="" /></center>
<center>图6-6-7: 通过PCIe直接进行设备间通信 (<a href=http://developer.download.nvidia.com/compute/cuda/4_0/CUDA_Toolkit_4.0_Overview.pdf>图片来源</a>)</center>


而在跨节点网络中也有类似的协议**GPUDirect
RDMA**，实现了GPU中的数据通过网络直接发送，无需系统内存中转，也实现了“零拷贝（zero-copy）”。但这里网络操作仍需CPU发起，因此与GPUDirect
P2P的纯GPU操作有所区别。

开启这项功能的条件，除了满足GPUDirect的基本条件之外，还需满足RDMA网卡与GPU也属于同一PCIe root。


<center><img src="./img/image41.png" width="600" height="" /></center>
<center>图6-6-8: GPUDirect RDMA 通信  (<a href=https://developer.nvidia.com/gpudirect>图片来源</a>）</center>

## 6.6.2 通信协调的软件

**分布式训练系统 通信库**

为了更好地服务深度学习等GPU任务，NVIDIA提出了针对其GPU等硬件产品的通信库**NCCL
: NVIDIA Collective Communication Library**。

<center><img src="./img/image42.png" width="600" height="" /></center>
<center>图6-6-9: GPU通信库的系统定位  (<a href=https://www.olcf.ornl.gov/wp-content/uploads/2019/12/Summit-NCCL.pdf>图片来源</a>） </center>


NCCL提供类似MPI的通信接口，包含集合式通信（collective communication）all-gather、 all-reduce、 broadcast、 reduce、reduce-scatter 以及点对点(point-to-point)通信send 和receive。

**拓扑感知的通信** NCCL这样的通信库中目前能够提供的通信算法主要针对已有的标准硬件，相对比较有限的，而有研究工作(例如: [SCCL](<https://github.com/microsoft/sccl>) )根据连接拓扑和带宽延迟等信息，可以综合设计性能更为优化的通信算法。

<center><img src="./img/image43.png" width="800" height="" /></center>
<center>图6-6-10: 常见的GPU互联结构下的通信拓扑 (<a href=https://www.olcf.ornl.gov/wp-content/uploads/2019/12/Summit-NCCL.pdf>图片来源</a>）</center>

除了NVIDIA之外，其它的厂商也发布了针对自身产品的高效通信库，例如AMD的[RCCL](<https://github.com/ROCmSoftwarePlatform/rccl>)以及intel的[OneCCL](<https://oneapi-src.github.io/oneCCL/>)。

随着硬件的快速发展，带来了更高的性能和更大的优化机遇，因此软件研究方面的迭代，尤其是支持分布式深度学习训练的算法硬件协同设计的研究，依然存在这巨大的潜力。


---------------------



## 小结与讨论

### 思考题：为什么模型训练通常需要分布式进行，而分布式模型预测并不常见？

* 计算模式不同：预测任务占用存储更小，更容易放在单个设备中

* 训练需要各个工作节点（Worker）保持通信，从而协调统一地**更新**模型参数；

* 预测中的模型参数是**固定**的，各个工作节点分别使用只读副本，无需相互通信协调

### 课后实验

本章的内容学习之后可以参考[实验7](../../Labs/AdvancedLabs/Lab7/README.md)进行对应的练习以加深理解。

## 参考文献

https://www.nvidia.com/en-us/data-center/a100

https://nvidia.com

Sylvain Jeaugey, NVIDIA, DISTRIBUTED DEEP NEURAL NETWORK TRAINING: NCCL ON SUMMIT https://www.olcf.ornl.gov/wp-content/uploads/2019/12/Summit-NCCL.pdf

https://www.microway.com/hpc-tech-tips/dgx-a100-review-throughput-and-hardware-summary/

https://techcommunity.microsoft.com/t5/azure-global/performance-considerations-for-large-scale-deep-learning/ba-p/2693834

OCP Summit https://146a55aca6f00848c565-a7635525d40ac1c70300198708936b4e.ssl.cf1.rackcdn.com/images/442f418201b7eb32089aa12895ee78977d03bea1.pdf

Enflame T10 Manual https://www.enflame-tech.com/support

http://developer.download.nvidia.com/compute/cuda/4_0/CUDA_Toolkit_4.0_Overview.pdf

https://techcommunity.microsoft.com/t5/azure-global/performance-considerations-for-large-scale-deep-learning/ba-p/2693834

https://developer.nvidia.com/gpudirect

https://github.com/microsoft/sccl
