<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 7.3 调度（Scheduling）

<center> <img src="./img/3/7-3-10-schedulemodule.png" ch="500" width="700" height="300" /></center>
<center>图7-3-0. 平台调度器</center>

在之前的章节，我们已经介绍集群管理中的运行时，但是作业在启动前，需要平台本身进行决策进而进行调度。如图中所示，本章将围绕经典可用于深度学习作业调度的传统平台调度算法进行介绍，期望让读者了解作业调度的经典问题和算法。

- [7.3 调度（Scheduling）](#73-调度scheduling)
  - [7.3.1 调度问题优化目标](#731-调度问题优化目标)
  - [7.3.2 单作业调度-群调度](#732-单作业调度-群调度)
  - [7.3.3 作业间调度-主导资源公平DRF(Dominant Resource Fairness)调度](#733-作业间调度-主导资源公平drfdominant-resource-fairness调度)
  - [7.3.4 组间作业调度-容量(Capacity)调度](#734-组间作业调度-容量capacity调度)
  - [7.3.5 虚拟集群(Virtual Cluster)机制](#735-虚拟集群virtual-cluster机制)
  - [7.3.6 抢占式调度(Preemptive Scheduling)](#736-抢占式调度preemptive-scheduling)
  - [7.3.7 深度学习调度算法实验与模拟研究](#737-深度学习调度算法实验与模拟研究)
    - [7.3.7.1 数据读取](#7371-数据读取)
    - [7.3.7.2 评测指标设定](#7372-评测指标设定)
    - [7.3.7.3 算法实现与评测](#7373-算法实现与评测)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)



## 7.3.1 调度问题优化目标

针对一批作业调度，常常考虑以下指标 :

- 吞吐(Throughput)：单位时间能完成的作业数量。平台希望吞吐量越大越好。 
- 完工时间(Makespan)：对一批作业，第一个作业到达到最后一个作业完成的整体时间，希望其越小越好，有些调度算法也考虑所有作业的整体完工时间作为优化目标，因为最小化完工时间(Makespan)等价于最大化资源效率(Efficiency)。
- 平均作业完成时间(Job Completion Time)：一批作业的平均完成时间，指标能够代表系统性能。例如，考虑分布式作业的局部性，影响通信时间，进而影响JCT。
- 资源利用率(Utilization) ：描述用于作业的资源占总资源的百分比。平台希望利用率越高越好。
- 资源碎片(Fragmentation)：作业分配后造成个别节点资源无法被再分 配，产生碎片问题。碎片越少，代表资源浪费越少。也是和资料利用率相关的指标。
- 平均响应时间(Average Response Time)：平均响应时间是从提交请求到产生第一个响应的时间量的平均。平台希望平均响应时间越短越好。 
- 排队延迟(Queuing Delay)：描述作业在调度器队列中等待资源分配所花费的时间，排队延迟越低，代表用户作业需要等待的时间越短，越高效。主要受两个因素影响，一个是公平性，由于用户作业用完所分配的配额，另一个是局部性（Locality）和资源碎片问题造成资源无法分配和等待。
- 公平性(Fairness)：资源使用在平台用户或组之间平均分配，而不是在作业之间平均分配。
- 服务水平协议(SLA)：服务级别协议 (SLA-service-level Agreement) 是服务提供商和客户之间的承诺。例如：服务的特定方面—公平性，质量、可用性、责任—在服务提供商和服务用户之间达成一致。
  
接下来，我们将通过经典的调度算法，看平台常用算法是如何解决遇到的问题的。

## 7.3.2 单作业调度-群调度

深度学习作业通常会持续数小时，有些甚至会持续数周。深度学习作业通常需要群调度，直到所有必需的加速设备都被授予后才能开始训练过程。 

如果不使用群调度会产生什么问题? 深度学习作业可以同时执行多个任务，如果有依赖任务没启动，已启动任务会在同步点忙于等待或者频繁上下文切换 (如下图所示)。首先会造成训练任务无法训练，由于等待不能启动的任务，如下图所示两个作业都申请了部分资源，但是还需要其他资源才能启动，产生了死锁现象。同时已启动的任务不释放资源，造成资源浪费。

<center> <img src="./img/3/7-3-2-gangscheduleproblem.png" ch="500" width="500" height="400" /></center>
<center>图7-3-1. 并行启动执行作业可能产生的问题</center>

群调度(Gang Scheduling) 的Wiki定义是：一种用于并行系统的调度算法，用于调度相关线程或进程,在不同处理器上同时启动并运行。 

接下来，对上面的问题实例，我们使用群调度(Gang Scheduling)同时启动深度学习任务进程。图中的A，B，C作业就可以交替执行，保证任务能顺利执行完。

<center> <img src="./img/3/7-3-3-gangschedule.png" ch="600" width="500" height="300" /></center>
<center>图7-3-2. 并行执行作业可能产生的问题</center>

当然群调度自身也有一定的局限性，群调度会增加资源碎片化的风险，并且在共享集群中利用率低。如图中t1,t2时间段，GPU 7和8就是空闲浪费的。

## 7.3.3 作业间调度-主导资源公平DRF(Dominant Resource Fairness)调度 

目前深度学习平台其实包含多种异构资源（CPU，GPU，主存等）以及被多用户使用是一个多租的环境。在调度过程中用户会细粒度的申请不同资源的用量，我们在满足用户异构资源需求的同时，也希望在多租的环境下兼顾一定的公平。

- 问题：包含异构资源类型的系统中如何进行多作业公平(Fairness)的资源调度？
- 挑战：相比传统单资源公平调度，深度学习作业也需要使用多种异构资源 (CPU, 主存, etc.)，并且需要调度GPU及GPU memory
  
DRF 使用优势资源的概念来比较多维（CPU, GPU, 内存等）资源。这个想法是在多资源环境中，资源分配应该由作业（用户或队列）的主导份额决定，这是作业已分配的任何资源（内存或 CPU）的最大份额。

本质上，DRF优化目标是寻求最大化所有实体的最小主导份额(Smallest Dominant Share)。

DRF调度策略：
1. 通过同类型资源在集群整体资源中的份额确定主导资源 (Dominant Resource)。
2. 基于最大最小公平（Max-Min Fairness）的针对多资源类型（e.g. GPU, CPU）的调度算法。

如下图所示实例，有Job 1和Job 2都在启动多个任务并申请多个资源。第一步先计算每个Job的主导资源。Job 1主导资源为Memory，Job 2主导资源是GPU。Job 1的优先级高于Job 2，因为Job 1份额0.4小于Job 2份额0.5。 

<center> <img src="./img/3/7-3-1-drf.png" ch="500" width="300" height="400" /></center>
<center>图7-3-3. 2个作业的DRF调度实例</center>


$$Cluster \  Resources: [10 \  GPU, 20GB \ RAM] $$

下面的资源申请需求下，主导资源是内存。
$$
Job \ 1: \\
$$
$$
Total \ GPU \ 1 + 1 = 2 \ GPU \\
$$
$$
GPU \ Share \ \frac{2}{10} = 0.2 \\
$$
$$
Total \ Memory \ 4 + 4 = 8GB \\
$$
$$
Memory \ Share \ \frac{8}{20} = 0.4 \\
$$
$$
Dominant \ resource \ is \ Memory
$$

下面的资源申请需求下，主导资源是GPU。
$$
Job \ 2:  \\
$$
$$
Total \ GPU \ 2 + 3 = 5 \ GPU \\
$$
$$
GPU \ Share \ \frac{5}{10} = 0.5 \\
$$
$$
Total \ Memory \ 2 + 2 = 4GB \\
$$
$$
Memory \ Share \ \frac{4}{20} = 0.2 \\
$$
$$
Dominant \ resource \ is \ GPU
$$


## 7.3.4 组间作业调度-容量(Capacity)调度

除了多个作业能够兼顾公平的分配，平台管理员还需要考虑如果是多个组共享平台，也需要兼顾组与组之间的公平性。如何让多个小组共享集群？
  - 能否为多个组织共享集群资源？
  - 共享集群资源的同时，如何同时为每个组织提供最小容量保证?
  - 空闲资源能否弹性为其他组织利用？
- 挑战：相比传统容量调度调度，深度学习作业也需要考虑调度GPU及GPU显存？
  
容量调度器在大数据平台常常作为主流调度器使用，从[作业类型角度](https://research.google/pubs/pub43438/)，大数据作业和深度学习训练作业，都可以看成是批处理作业。它允许多租户安全地共享一个大型集群，以便在分配容量的限制下及时为他们的应用程序分配资源。 

我们看下图实例，图中组（Team） A，B，C共享集群，每个组有多个用户，每个用户都会提交作业使用集群资源。如果不考虑组间公平性，Team A再申请了45\%的资源后，如果没有使用造成浪费的同时，也会让Team C对资源无法申请，产生[饥饿(Starvation)](https://en.wikipedia.org/wiki/Starvation_(computer_science))现象。

<center> <img src="./img/3/7-3-4-capaproblem.png" ch="500" width="500" height="400" /></center>
<center>图7-3-4. 资源占用过多造成其他组无法分配资源问题</center>

所以，为了支持支持多租(Multi-Tenant）资源共享，容量调度被设计出来。

容量调度策略集合：
- 提升利用率（Utilization）: 
  - 虚拟集群(Virtual Cluster)：组能看到视图是虚拟资源，并不绑定具体机器，等作业启动后分配相应的资源，这样有助于提升资源利用率。
  - 层级队列(Hierarchical Queues): 支持队列分层结构，以确保在允许其他队列使用空闲资源之前在组织的子队列之间共享资源，从而提供更多的控制和可预测性。 
  - 队列内可以正交组合其他作业间调度算法，例如，先进先出（FIFO），DRF等。对异构计算场景，扔可以采用适合多维资源调度或其他自定义调度器。满足下面介绍的约束情况下，仍旧可以采用DRF等调度策略进行具体作业之间的调度与资源分配。
- 多租与提升公平性(Fairness):
  - 多租与用户限制因素(User Limit Factor)：
    - 从某种意义上说，队列将分配到网格容量的一小部分，因为它们可以使用一定容量的资源。 提交到队列的所有应用程序都可以访问分配给队列的容量。管理员可以对分配给每个队列的容量配置软限制和可选的硬限制。 
    - 允许多用户多组以多租形式使用集群。控制单用户的可以消耗的最大资源，放止占用资源过多，造成其他进程无法申请资源。
- 弹性(Elasitcity)和SLA 
  - 奖励资源(Bonus Resource)：对其他组没有使用的资源可以临时免费出让给有需要的团队，但是当资源持有者需要，则需要抢占资源归还给持有者。
  - 抢占(Preemption)：配合奖励资源使用，保证对用户提供的服务等级协议（SLA）。

如下图所示，当管理员配置了最小和最大的组使用资源限额，这样保证组与组之间都有资源可用。

<center> <img src="./img/3/7-3-5-capascheduling.png" ch="500" width="400" height="300" /></center>
<center>图7-3-5. 容量调度</center>

***经典回顾***

操作系统[公平共享调度（Fair-share scheduling）](https://en.wikipedia.org/wiki/Fair-share_scheduling)是一种用于计算机操作系统的调度算法，其中 CPU 使用率在系统用户或组之间平均分配（或演变为类似容量调度，组之间按比例分配配额），而不是在进程之间平均分配资源。在逻辑上实现公平共享调度策略的一种常见方法是在每个抽象级别（进程、用户、组等）递归应用轮询调度（Round-Robin）策略，例如，两个公平分配的组，组内用户再根据轮训或其他调度算法进行调度。所以我们看到有的时候调度算法具有一定的正交性，可以嵌套使用，关键是在不同抽象级别上应用不同的策略。

## 7.3.5 虚拟集群(Virtual Cluster)机制

在这些集群内，一般组和用户所看到的的资源并没有绑定到具体的物理机器，而是在调度后决定作业启动的物理机器。这背后是通过虚拟集群 (Virtual Cluster) 映射所实现的。而虚拟集群和我们之前介绍的控制组（Cgroups）的目的和设计较为类似。我们会看到很多集群产生的问题，在传统的操作系统中都能找到类似的设计问题与原则。

如下图所示，虚拟集群会在配置用户组的配额和视图，物理集群是在调度后在运行时绑定的。这样可以大幅提升资源利用率。

<center> <img src="./img/3/7-3-6-vc-bind.png" ch="500" width="700" height="300" /></center>
<center>图7-3-6. 虚拟集群和物理集群映射与绑定</center>

针对深度学习的细粒度虚拟集群策略：
- 虚拟集群根据小组的配额进行定义
- 每个租户(Tenant)构成了一个虚拟集群(VC)
- 资源被分配给租户(Tenant)
- 将虚拟集群映射到物理集群

<center> <img src="./img/3/7-3-7-vc-define.png" ch="600" width="700" height="600" /></center>
<center>图7-3-6. 虚拟集群资源分配</center>

***经典回顾***

虚拟集群的设计思想类似传统操作系统中的控制组（Cgroups）的思路，约束资源但是解耦和物理资源的绑定。操作系统[控制组（Cgroups）](https://man7.org/linux/man-pages/man7/cgroups.7.html)是Linux内核的一个功能，用来限制、控制与分离一个行程群组的资源（如CPU、内存、磁盘输入输出等），让不同组织，用户的不同进程在操作系统中有相应的资源约束，但是不于具体硬件资源绑定，而是由运行时调度分配。

## 7.3.6 抢占式调度(Preemptive Scheduling)

一些集群管理员为了减少组空闲资源造成的浪费，想共享空闲资源，但是单纯出让资源但是不能保证原有用户随时要回会产生相应新的问题，不能保证对原用户的SLA （Service Level Agreement）。所以一般通过抢占调度解决。抢占调度也适合，需要保证其他作业相应时间的场景。

如下图所示，如过APP2长时间无法得到资源，则无法执行，而其执行时间实际很短。这就需要通过抢占机制进行调度。让APP2获取一定资源执行，保证降低平均响应时间。

<center> <img src="./img/3/7-3-8-preemptive.png" ch="500" width="400" height="300" /></center>
<center>图7-3-7. 作业等待时间过长问题</center>

下图所示，我们可以看到，A队列中配置可用为10资源，但是由于集群有空闲资源，多实用了20奖励资源给C6和C7，这时C队列需要使用20资源，而且集群应该保证，这时会触发抢占。当APP1的C6和C7使用的资源被标记为可以被抢占后，其资源可以通过以下步骤被抢占：
1. 从过度使用的队列中获取需要被抢占的容器(队列A的C6和C7)。
2. 通知作业(队列A)控制器即将触发抢占。
3. 等待直到被抢占终止运行。

<center> <img src="./img/3/7-3-9-preemptive.png" ch="500" width="500" height="400" /></center>
<center>图7-3-8. 抢占调度</center>

抢占式调度对深度学习作业的挑战：在深度学习作业下，被抢占的作业当前只能失败，默认情况下无法像传统操作系统进行上下文切换。目前有些工作中会提供框架或设备驱动库层的检查点机制，配合调度器实现强占与恢复，但是由于本身不是原生支持，所以有一定开销且支持的框架与场景有限并未大范围使用。未来可以设计更好的深度学习检查点和恢复技术进行减少抢占后作业失效造成之前作业的训练资源无效使用的问题。

***经典回顾***

- [操作系统强占调度](https://en.wikipedia.org/wiki/Preemption_(computing))：在计算中，抢占（Preemption）是暂时中断正在执行的任务的行为，目的是在以后恢复它。这个中断（Interrupt）是由外部调度器完成的，没有任务的参与。这种抢占式调度器通常运行在最高特权的保护环中。处理器当前执行任务的这种变化称为上下文切换（Context Switching），读者思考深度学习作业强占是否能支持上下文切换？如今，几乎所有操作系统都支持[抢占式多任务处理](Preemptive Multitasking)，例如Windows、macOS、Linux等。最初开发多任务处理技术是为了允许多个用户共享一台机器，也就是我们说的多租，但很快就发现，无论用户数量如何，多任务处理都非常有用。多任务处理使单个用户可以同时运行多个应用程序，或者在保留对计算机的控制权的同时运行"后台"进程。
  
## 7.3.7 深度学习调度算法实验与模拟研究

读者可以通过本实例的练习，通过真实的痕迹（Traces），进行以上调度算法模型，或研究新的面向深度学习的调度算法。
此开源数据集[philly-traces](https://github.com/msr-fiddle/philly-traces) 包含 Microsoft 内部 Philly集群上第一方 (First-Party) DNN 训练工作负载的代表性子集。 数据是 ATC’19 中“Analysis of large-scale multi-tenant GPU clusters for DNN training workloads”中描述的工作负载的一个脱敏数据子集。 这项工作是作为 Microsoft Research 的 Project Fiddle 的一部分完成的。

### 7.3.7.1 数据读取
读者可以参考库中提供的脚本读取数据并了解数据模式。
### 7.3.7.2 评测指标设定
读者可以根据本章开始介绍的指标设计优化目标。
### 7.3.7.3 算法实现与评测
读者可以选用以上介绍的经典算法作为基准测试，设计新的算法，并通过真实平台数据模拟，看能否提升当前目标，超越基准算法，并进行结果分析，形成分析报告或论文。

## 小结与讨论

本章我们主要介绍异构计算集群管理系统的传统经典算法，这些算法并没有随着新的面向深度学习的调度算法出现而废弃，在相应的场景依然发挥作用，我们可以看到经典理论和技术的魅力并经得起时间的考验。

请读者思考，如果让你设计调度算法，当前场景还有哪些不足？

## 参考文献

- [Analysis of Large-Scale Multi-Tenant GPU Clusters for DNN Training Workloads](https://dl.acm.org/doi/10.5555/3358807.3358888)
- [Multi-tenant GPU Clusters for Deep Learning Workloads: Analysis and Implications](https://www.microsoft.com/en-us/research/uploads/prod/2018/05/gpu_sched_tr.pdf)
- [Gandiva: Introspective Cluster Scheduling  for Deep Learning](https://dl.acm.org/doi/10.5555/3291168.3291212)
- [Dominant Resource Fairness: Fair Allocation of Multiple Resource Types](https://cs.stanford.edu/~matei/papers/2011/nsdi_drf.pdf) 
- [All You Need to Know about Scheduling Deep Learning Jobs](https://www.sigops.org/src/srcsosp2017/sosp17src-final35.pdf) 
- https://github.com/microsoft/pai
- https://www.kubeflow.org/ 
- [Kubeflow Pipelines With GPUs](https://betterprogramming.pub/kubeflow-pipelines-with-gpus-1af6a74ec2a)
- [YARN – The Capacity Scheduler](https://hadoop.apache.org/docs/stable/hadoop-yarn/hadoop-yarn-site/CapacityScheduler.html)
- [Better SLAs via Resource-preemption in YARN’s Capacity Scheduler](https://blog.cloudera.com/better-slas-via-resource-preemption-in-yarns-capacityscheduler/)
- [Kube-Batch: Dominant Resource Fairness (DRF)](https://github.com/kubernetes-sigs/kube-batch/blob/master/doc/design/plugin/drf.md)
- https://docs.cloudera.com/HDPDocuments/HDP2/HDP-2.4.3/bk_yarn_resource_mgt/content/ref-4c095638-c9ce-487a-b42d-eab26fd58b9c.1.html
- https://research.google/pubs/pub43438/

