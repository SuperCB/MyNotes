<!--Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/microsoft/AI-System/blob/main/LICENSE)版权许可-->

# 7.5 存储

<center> <img src="./img/5/7-5-10-storagerelated.png" ch="500" width="700" height="300" /></center>
<center>图7-5-0. 平台存储 </center>

在之前的章节，我们已经介绍面向深度学习的集群管理系统的运行时与调度。如图7-5-0，本章将围绕平台中的存储，文件系统来展开。计算，存储与网络是构成平台的重要基本组件，在深度学习系统中，我们常常关注计算与网络，却忽视存储的重要性。本章将围绕平台中的存储内容展开。

- [7.5 存储](#75-存储)
- [7.5.1 沿用大数据平台存储路线](#751-沿用大数据平台存储路线)
- [7.5.2 沿用高性能计算平台存储路线](#752-沿用高性能计算平台存储路线)
- [7.5.3 面向深度学习的存储](#753-面向深度学习的存储)
  - [小结与讨论](#小结与讨论)
  - [参考文献](#参考文献)

# 7.5.1 沿用大数据平台存储路线

当前一部分人工智能平台工程师拥有大数据平台开发背景或平台本身归于或衍生于大数据平台组，所以有些平台文件系统和存储选型时沿用大数据平台的存储策略作为初始的平台存储方案。

- Hadoop分布式文件系统 ([HDFS](https://hadoop.apache.org/hdfs/)):例如，开源人工智能平台OpenPAI中采用HDFS作为存储方案。HDFS是一种分布式文件系统，最初是作为 Apache Nutch 网络搜索引擎项目的基础设施而构建的，是广泛用于大数据系统的文件系统。它与已有的分布式文件系统有很多相似之处。HDFS 通过副本机制，具有高度容错性，旨在部署在低成本硬件上。HDFS 提供对应用程序数据的高吞吐量访问，适用于拥有大量数据集的应用程序。HDFS 放宽了一些 POSIX 要求，以支持对文件系统数据的流式访问。HDFS本身适合顺序读写，不适合随机读写，不建议对小文件访问，主要为主存访问磁盘而设计，没有针对GPU显存和主存之间的数据读写进行特定支持和优化，这些劣势会造成深度学习负载下的一些性能问题和瓶颈。
<center> <img src="./img/5/7-5-3-duplication.png" ch="500" width="700" height="400" /></center>
<center>图7-5-1. Hadoop HDFS架构和副本机制(<a href="https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html">图片来源</a>)</center>

如图所示，像HDFS这类分布式文件系统，一般通过主（图中Namenode）- 从（图中Datanodes）架构，主节点负责整体资源管理，负载均衡，请求调度，从节点负责管理对应服务器的数据管理。其中每个客户端（Client）的文件读写会通过主节点分发到从节点进行数据读写。每个文件会被拆分成数据块（Block），并通过副本（Replication）机制，在多态节点留有冗余备份，当节点失效（Failure），能够恢复。这也是之前第一章介绍的冗余（Redundancy）在系统可靠性（Dependability）设计中的应用。

但是HDFS应用到深度学习平台扔存在一些问题需要注意。对深度学习框架来说，原生对大数据存储系统接口支持并不充分，造成有些框架需要自己定义自定义数据读取器，相比大数据框架效率低，实现容易性能差。更多的是用户通过FUSE挂载方式将其挂载到节点上使用。以上两种方式都没有像原生大数据框架一样在读取器层就考虑数据局部性（Locality），减少数据搬运开销，同时用户使用习惯不同容易产生小文件读写的造成性能低下的执行行为。从硬件角度，GPU显存和磁盘间还有一层主存，这部分的缓存处理逻辑也抛给了用户和框架，容易造成性能问题。

- 云有云平台采用云存储，例如，微软Azure云平台中的Azure Blob，亚马逊云平台中的S3等。对于基础架构部署于公有云平台的公司，云平台提供的文件系统不失为一个较好的选择，并通过用户空间文件系统（[Filesystem in Userspace](https://en.wikipedia.org/wiki/Filesystem_in_Userspace)）简称FUSE或者HDFS兼容的访问接口和协议进行访问。云平台的存储提供冗余备份保证可靠性，并通过数据中心高速网络的支持，提供近似本地存储的高速存储访问带宽。但是其通常为通用场景所设计，其FUSE等接口一般为外围工具而开发设计，没有对深度学习负载和特点提供定制化的优化和支持。

<center> <img src="./img/5/7-5-5-fuse.png" ch="500" width="500" height="500" /></center>
<center>图7-5-2. 用户空间文件系统（Filesystem in Userspace）访问云端存储（例如，Azure Blob）(<a href="https://en.wikipedia.org/wiki/Filesystem_in_Userspace">图片来源</a>)</center>

上图显示FUSE工作原理的流程图：来自用户空间的列出文件的请求 (ls -l /tmp/fuse) 被内核通过虚拟文件系统([Virtual File System](https://en.wikipedia.org/wiki/Virtual_file_system))简称VFS重定向到FUSE。FUSE 然后执行注册的处理程序（./hello）并将请求传递给它（ls -l /tmp/fuse）。通过REST API或其他接口调用读写云端存储(例如Blob Fuse)。处理程序将响应返回给 FUSE，然后将其重定向到最初发出请求的用户空间程序。例如，很多分布式文件系统都提供了FUSE功能方便用户使用，我们以Azure提供的[BlobFuse](https://github.com/Azure/azure-storage-fuse)为例：

用户或平台系统只需要挂载文件系统即可。例如，参考官方实例的步骤: 

```shell
# 1. 安装blobfuse后，配置环境变量使用帐户名和密钥进行身份验证：

export AZURE_STORAGE_ACCOUNT=myaccountname
export AZURE_STORAGE_ACCESS_KEY=myaccountkey

# 2. 建议使用高性能磁盘或ramdisk作为BlobFuse的本地缓存。

mkdir -p /mnt/blobfusetmp
chown <myuser> /mnt/blobfusetmp

# 3. 创建挂载点 
mkdir /path/to/mount 

# 4. 使用blobfuse挂载一个Blob容器（必须已经创建）：

blobfuse /path/to/mount --container-name=mycontainer --tmp-path=/mnt/blobfusetmp
```
挂载后，用户就可以像访问本地文件目录一样，访问/path/to/mount中的数据了。其他分布式文件系统也提供类似的功能供用户进行挂载和使用文件系统。

- [Alluxio](https://www.alluxio.io/)是基于内存的分布式存储，可以充当分布式缓存服务。业界也有一些平台公司通过Alluxio管理分布式主存并提供数据缓存和备份功能。由于存储层级上，GPU显存和主存最为接近，提供主存层的缓存可以大幅加速I/O。但同时我们也应该看到，平台方也需要注意持久化的支持和策略设计。

如图所示，Alluxio不是简单的将整个数据集复制到每台机器中，而是实现了共享的分布式缓存服务，其中数据可以均匀地分布在集群中。这可以大大提高存储利用率，尤其是当训练数据集远大于单个节点的存储容量时。同时也可以基于Alluxio在单机存储中设计和达到重复数据删除(<a href="https://en.wikipedia.org/wiki/Data_deduplication">Data  Deduplication</a>)效果。

<center> <img src="./img/5/7-5-4-cache.png" ch="500" width="400" height="400" /></center>
<center>图7-5-3.通过分布式内存缓存数据，构建与其他分布式文件系统的混合存储方案 (<a href="https://www.alluxio.io/blog/machine-learning-training-with-alluxio-solution-overview/">图片来源</a>)</center>

如图，业界有团队（例如，微软Bing，Bilibili等）使用 Alluxio 加速大规模机器学习和深度学习离线（Offline）推理（Inference）任务。通过部署Alluxio，他们能够加快推理工作，减少I/O停顿，并将性能提高。如图所示，Alluxio作为分布式缓存，可以缓存来自不同的存储数据，例如，Azure Blob文件系统，HDFS文件系统等。


# 7.5.2 沿用高性能计算平台存储路线

由于深度学习平台本身硬件以GPU和InfiniBand网卡为核心硬件，其技术栈和高性能计算或超算集群高度相似，所以很自然也有很多平台团队会选择使用高性能计算平台中常用的存储方案沿用到深度学习平台中使用。以下文件系统也是通常可以选用的方案：

- 网络文件系统（Network File System）简称NFS文件系统是由Sun公司研发的网络文件系统，其基本原理是将某个设备本地文件系统通过以太网的方式共享给其它计算节点使用。也就是说，计算机节点通过NFS存储的数据是通过网络存储在另外一个设备，而不是存储在本地磁盘。其比较适合在平台部署早期提供文件系统支持，方便部署，技术成熟，访问接口优化，挂载到计算节点提供给算法工程师友好的体验。不足是随着数据量的增长，难以支持更大的存储空间和访问吞吐，同时权限管理需要平台层协同设计进行管理。例如，很多团队小规模平台中或者针对特定的租户部署和采用 NFS 作为存储方案。

<center> <img src="./img/5/7-5-1-nfs.png" ch="500" width="400" height="200" /></center>
<center>图7-5-4. NFS实例，客户端将NFS挂载到本地/nfs目录(<a href="https://advishnuprasad.com/blog/2016/03/29/setup-nfs-server-and-client-using-ansible/">图片来源</a>)</center>

如图所示，当通挂载（Mount），用户可以在本地服务器通过 NFS 客户端访问存储服务器，进而像使用本地磁盘一样进行数据访问。

- [Lustre](https://www.lustre.org/)文件系统是高性能计算平台部署最为广泛的商用文件系统。Lustre 是一种并行分布式文件系统，一般用于大规模高性能集群计算场景。Lustre 这个名字是源自 Linux 和集群（Cluster）的组合词。自 2005 年 6 月以来，Lustre 一直被前十名中的至少一半、世界上最快的 100 台超级计算机中的 60 多台使用。Lustre原生支持和利用InfiniBand（IB）高速网卡，可以利用深度学习平台中的IB网络，提供更加高效的数据访问。同时支持高性能的mmap() I/O调用，容器化的支持与数据隔离，小文件的支持等，一系列的优化使得Lustre在人工智能场景也取得了不俗的性能和用户体验。在公有云场景，亚马逊AWS也推出了Amazon FSx服务，作为一项完全托管的服务，[Amazon FSx](https://docs.aws.amazon.com/fsx/latest/LustreGuide/what-is.html)让用户可以更轻松地将 Lustre 用于存储速度很重要的工作负载。FSx for Lustre 消除了设置和管理 Lustre 文件系统的传统复杂性，使用户能够在几分钟内启动并运行经过测试的高性能文件系统。

<center> <img src="./img/5/7-5-2-lustre.png" ch="500" width="900" height="400" /></center>
<center>图7-5-5. Lustre架构，其使用高速网卡加速数据平面读写(<a href="https://wiki.lustre.org/Introduction_to_Lustre">图片来源</a>)</center>

如图所示，我们可以看到Lustre通过InfiniBand等高速网卡互联元数据（Metadata）服务器和对象存储（Object Storage）服务器，并能够提供高达1~100000+的客户端访问量支持。

# 7.5.3 面向深度学习的存储

首先我们通过一个PyTorch实例来看，在深度学习作业中是如何读取数据以及和文件系统打交道的。

```python
# 本实例抽象自https://github.com/pytorch/examples/blob/main/mnist/main.py

def train(args, model, device, train_loader, optimizer, epoch):
    ...
    # （3）每次从数据加载器读取一个批次的样本
    for batch_idx, (data, target) in enumerate(train_loader):
        # （4）如果当前device是GPU，下面代码将样本由主存传输到GPU显存
        data, target = data.to(device), target.to(device)
        ...
        # （5）模型处理输入数据进行前向传播计算
        output = model(data)
        # 训练部分代码
        ...  

def main():
    ... 
    # （1）从../data文件夹读取, /data可能是存在共享的文件系统，通过fuse挂载到本地，也可能是本地文件夹存储下载到本地磁盘的数据
    dataset1 = datasets.MNIST('../data', train=True, download=True,
                       transform=transform)
    dataset2 = datasets.MNIST('../data', train=False,
                       transform=transform)
    # （2）框架本身提供的数据加载器，一般可以支持并行读取等优化
    train_loader = torch.utils.data.DataLoader(dataset1,**train_kwargs)
    test_loader = torch.utils.data.DataLoader(dataset2, **test_kwargs)
    ... 
    for epoch in range(1, args.epochs + 1):
        train(args, model, device, train_loader, optimizer, epoch)
        test(model, device, test_loader)
    ... 
```

通过以上实例我们可以观察到，深度学习场景下，首先从硬件来说，内存层级以GPU显存为传统主存的地位，硬盘和GPU显存之间还有主存中转数据，与GPU显存最近的存储并不是像之前和主存交互的块存储设备。从深度学习作业访存特点是，迭代式执行不断读取一个批次（Batch）的数据，并且访存模式受每轮数据随机洗牌（Shuffle）的影响是随机读取。从数据结构来看，数据大部分场景下为统一格式规整的张量。同时每次读取的数据并没有像数据库或者大数据系统的针对特定列的过滤机会。从用户侧用户体验与开发水平的现状出发，用户也更倾向于使用单机文件系统一样通过FUSE方式进行数据访问。

**数据读取预估练习与思考**：我们通过如下预估实例，思考和启发读者关于针对深度学习存储的优化：
```python
# 1) 基准预估读batchsize = 1024个样本需要多久
# seconds_per_seek: 从开始读取到读到第一个字节的寻找时间
# per_sample_size: 每个训练样本的大小，单位为字节
# bus_bandwidth: 磁盘或者网络存储等读带宽
1024 (seeks) * seconds_per_seek + 1024 * per_sample_size / bus_bandwidth = per_batch_read_time

# 2) 如果我们将1024个样本变成一批次进行读取需要多久?
1 (seek) * seconds_per_seek + 1024 * per_sample_size / bus_bandwidth = per_batch_read_time

# 当前实例启发我们通过1）内存数据打包为一个张量和批处理进行性能提升 2）设计高效的文件格式减少小文件随机读写问题

# 3) 如果我们并行使用32个线程进行读取需要多久?
1 (seek) * seconds_per_seek + (1024 / 32) * per_sample_size / bus_bandwidth = per_batch_read_time

# 当前预估启发我们思考并行的数据加载器设计

# 4) 如果我们有主存缓存需要读多久？假设PCIe带宽为磁盘或者云存储带宽的K倍。
pcie_bandwidth = bus_bandwidth / k
1 (seek) * seconds_per_seek + (1024 / 32) * per_sample_size / pcie_bandwidth = per_batch_read_time

# 当前预估启发我们思考利用主存作为磁盘缓存尽可能将数据放在内存预取以及流水线机制进行性能优化

# 5) 如果我们知道需要读取的数据位置，访问主存的缓存失效率(cache miss rate)为P，那么当前的读取时间是多少？

P * (1 (seek) * seconds_per_seek + (1024 / 32) * per_sample_size / pcie_bandwidth) + (1 - P) * (1 (seek) * seconds_per_seek + (1024 / 32) * per_sample_size / bus_bandwidth) = per_batch_read_time

# 当前预估启发我们思考利用深度学习作业访存局部性进行性能优化

# 6) 其他潜在优化

6.1) per_sample_size部分，读者可以思考是否可以通过压缩，量化等技术降低数据大小进而提升？
6.2) seconds_per_seek部分，由于磁盘对顺序读取和随机读取性能不同，读者可以思考是否有更好的文件格式设计最大化顺序读最小化随机读？ 

```
以上的特点造成看似对存储优化机会不像传统的数据库或者大数据系统机会多，但是如果不设计好面向深度学习的存储，也会造成和产生系统瓶颈。

所以可以朝着以下几个方向，并利用已有成熟的文件系统设计思想，与数据加载器（Data Loader）和底层硬件协同设计（Co-design）出面向深度学习的高效率块存储I/O技术栈，一站式加速深度学习作业的数据加载：

<center> <img src="./img/5/7-5-7-overviewofio.png" ch="500" width="1300" height="500" /></center>
<center>图7-5-6. 深度学习I/O时序图与优化策略总览(<a href="">图片来源</a>)</center>

- 高效文件格式（Layout）的设计：一般文件格式有几点设计思路（1）合并为大文件，减少文件数量，减少文件打开开销。（2）减少随机读写转为顺序读写。（3）高效的格式和序列化库，降低序列化与反序列化开销。例如，[TFRecord](https://www.tensorflow.org/tutorials/load_data/tfrecord)等针对深度学习负载设计的文件格式，将原来多张图片（每个都是一个文件），序列化为一个二进制文件。
- 并发执行（Concurrent Computing）和并行（Parallel）加载：I/O和计算形成流水线协同配合，减少I/O成为瓶颈的几率，同时利用多核进行并行加载。如图所示，未经优化的数据加载流程，一个训练迭代含有三个阶段：文件打开（Open），迭代每个批次读取（Read）数据和训练（Train）。框架原生支持跨多种数据源并能异步与并行数据加载的高性能数据加载器模块，例如，并发执行的[TensorFlow Data API](https://www.tensorflow.org/guide/data_performance)。并行执行的PyTorch数据加载器（Dataloader）。

<center> <img src="./img/5/7-5-8-prefetched.png" ch="500" width="1300" height="600" /></center>
<center>图7-5-7. 预取优化的数据读取时序图(<a href="https://www.tensorflow.org/guide/data_performance">图片来源</a>)</center>

- 统一文件系统接口（Unified File System API）：对用户透明，统一管理多级，多数据源异构存储。
  - [NVIDIA AIStore](https://github.com/NVIDIA/aistore)：AIStore（简称AIS）是一个为人工智能负载设计的轻量级存储堆栈。减少内核态切换与CPU中断，减少内核与用户态内存拷贝。可以部署为远程存储的基于 LRU 的快速缓存。可以按需填充预取和下载 API，适用于集群内大量用户可能会重复使用数据集的场景。自动重新平衡集群（通过类Map Reduce扩展），在集群成员、驱动器故障和附件、存储桶重命名发生任何变化时自动触发，因为用户不断产生新数据与模型，删除旧模型，造成文件系统容易变得不平衡。支持关联处理（Associative Processing），用户的ETL可以就近数据处理，数据中心流行计算存储分离，ETL通过关联处理可以减少I/O数据搬运。工程上，兼容支持按需挂载多种云存储，K8s部署，数据保护，纠删码，高可用等分布式文件系统功能。
  
<center> <img src="./img/5/7-5-6-aistore.png" ch="500" width="600" height="300" /></center>
<center>图7-5-8. AIStore支持挂载多种存储，统一管理(<a href="https://github.com/NVIDIA/aistore">图片来源</a>)</center>

- 局部性（Locality）：（1）已知访问顺序（时间局部性）的情况下的预取（Prefetch）策略的支持。例如，虽然深度学习数据读取为随机读取样本，但是一定程度上如果随机数生成如果不依赖当前Epoch，可以考虑提前生成随机序列并由守护线程进行数据提前加载与准备。（2）利用数据中心主存不断增长的趋势，在主存或挂载高速二级存储（NVM等）做好数据缓存和备份，并由分布式缓存文件系统纳入统一管理。例如，业界有公司利用Alluxio提供缓存功能。
- 内核旁路（Kernel Bypassing）：
  - [GPUDirect存储器](https://developer.nvidia.com/zh-cn/blog/gpudirect-storage/)：底层利用RMDA直接访问，RDMA支持零拷贝，内核旁路（用户态I/O）进而大幅提高I/O效率，直接访问远端高速存储（例如，NVMe），在网络和块存储I/O上协同优化。其避免了通过主存中的缓冲区的额外拷贝，并使网卡存储器附近的直接内存访问（DMA）引擎能够在直接路径上将数据移入或移出 GPU 内存所有这些都不会给 CPU（不干扰DMA）或 GPU （不干扰GPU DMA）带来负担。
  
<center> <img src="./img/5/7-5-9-gpudirect.png" width="1000" height="600" /></center>
<center>图7-5-9. GPUDirect 存储器(<a href="https://developer.nvidia.com/zh-cn/blog/gpudirect-storage/">图片来源</a>)</center>

- 卸载（Offloading）：可以将一定的数据压缩解压缩，反序列化，甚至一定的数据预处理等计算卸载到协处理器。
  - ETL卸载到 GPU:（[DALI](https://docs.nvidia.com/deeplearning/dali/user-guide/docs/)） 提供了一组高度优化的构建块，用于加载和处理图像、视频和音频数据。DALI 通过将数据预处理卸载到 GPU 来解决 CPU 瓶颈问题。此外，DALI 利用预取、并行执行和批处理等功能为用户透明地加速处理数据。NVDIA还通过[NVTabular加速推荐引擎ETL](https://resources.nvidia.com/en-us-merlin/accelerating-recsys-etl-blog?lx=97GH0Q)。
  - DMA卸载：例如，GPUDirect卸载DMA复制引擎到NIC或NVMe内的DMA处理，减轻 CPU，GPU DMA负担。
- 数据与模型隐私保护：本章暂不介绍数据和模型的隐私保护，读者可以参考第13章内容。

其他例如权限管理等和传统文件系统区别不太，读者可以参考传统文件系统设计进行借鉴。
  
## 小结与讨论

本章我们主要介绍异构计算集群管理系统的中的存储，我们在深度学习系统中往往开始关注计算和网络较多，但随着时间的推移会意识到存储的重要性和新的问题。

请读者思考，当前是否有必要设计一款针对深度学习场景的文件系统？

## 参考文献
- https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html
- https://www.alluxio.io/
- https://en.wikipedia.org/wiki/Network_File_System
- https://azure.microsoft.com/en-us/services/storage/blobs/
- https://aws.amazon.com/s3/
- https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/lustre-performance-superior-to-hdfs-white-paper.pdf
- https://wiki.lustre.org/Infiniband_Configuration_Howto
- https://www.hpcadvisorycouncil.com/pdf/Lustre_Best_Practice.pdf
- https://www.sc-asia.org/2018/wp-content/uploads/2018/03/1_1700_Carlos-Thomaz.pdf